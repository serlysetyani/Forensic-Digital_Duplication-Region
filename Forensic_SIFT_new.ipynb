{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/serlysetyani/Forensic-Digital_Duplication-Region/blob/main/Forensic_SIFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "xh6AatgKIBUY",
    "outputId": "abf887f4-d34a-4526-e75e-279d689c2a3f"
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"photo-1559736220-66fc1882555d-F2.jpg\")\n",
    "h, w, c = img.shape\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.SIFT_create(nfeatures=100000, nOctaveLayers=7, sigma=1.6)\n",
    "keypoints, descriptors = sift.detectAndCompute(img_gray, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "matches = bf.knnMatch(descriptors, descriptors, k=3)\n",
    "\n",
    "better_matches = []\n",
    "for a, b, c in matches:\n",
    "    if a.trainIdx == a.queryIdx:\n",
    "        better_matches.append([b, c])\n",
    "    elif b.trainIdx == b.queryIdx:\n",
    "        better_matches.append([a, c])\n",
    "    elif c.trainIdx == c.queryIdx:\n",
    "        better_matches.append([a, b])\n",
    "\n",
    "ratio_thresh = 0.5\n",
    "good_matches = []\n",
    "for m, n in better_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "\n",
    "MIN_MATCH_COUNT = 3\n",
    "if len(good_matches) > MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([keypoints[m.trainIdx].pt for m in good_matches])\n",
    "    dst_pts = np.float32([keypoints[m.queryIdx].pt for m in good_matches])\n",
    "\n",
    "    retval, inliers = cv2.estimateAffine2D(src_pts, dst_pts, method=cv2.RANSAC, ransacReprojThreshold=3, maxIters=100,\n",
    "                                           confidence=0.99)\n",
    "\n",
    "    matchesMask = inliers.ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matches = []\n",
    "for i in range(len(good_matches)):\n",
    "    if matchesMask[i] == 1:\n",
    "        final_matches.append(good_matches[i])\n",
    "\n",
    "img_RGB = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "list_point1 = []\n",
    "list_point2 = []\n",
    "for j in final_matches:\n",
    "\n",
    "    # Get the matching keypoints for each of the images\n",
    "    point1 = j.trainIdx\n",
    "    point2 = j.queryIdx\n",
    "\n",
    "    # Get the coordinates, x - columns, y - rows\n",
    "    (x1, y1) = keypoints[point1].pt\n",
    "    (x2, y2) = keypoints[point2].pt\n",
    "\n",
    "    # Append to each list\n",
    "    list_point1.append((int(x1), int(y1)))\n",
    "    list_point2.append((int(x2), int(y2)))\n",
    "\n",
    "    # Draw a small circle at both co-ordinates: radius 4, colour green, thickness = 1\n",
    "    # copy keypoints circles\n",
    "    cv2.circle(img_RGB, (int(x1), int(y1)), 4, (0, 255, 0), 1)\n",
    "    # original keypoints circles\n",
    "    cv2.circle(img_RGB, (int(x2), int(y2)), 4, (0, 255, 0), 1)\n",
    "\n",
    "    # Draw a line in between the two points, thickness = 1, colour green\n",
    "    cv2.line(img_RGB, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapAffine_img = cv2.warpAffine(img_gray, retval, (w, h))\n",
    "cv2.imwrite('res.png', wrapAffine_img)\n",
    "\n",
    "blank_image = np.zeros((h, w, 1), np.uint8)\n",
    "\n",
    "for y in range(0, h-3):\n",
    "    for x in range(0, w-3):\n",
    "        window1 = img_gray[y: y+3, x: x+3]\n",
    "        window2 = wrapAffine_img[y: y + 3, x: x + 3]\n",
    "        a1 = window1[1][1]\n",
    "        a2 = window2[1][1]\n",
    "        mean1 = cv2.mean(window1)\n",
    "        mean2 = cv2.mean(window2)\n",
    "        mean1_num = mean1[0]\n",
    "        mean2_num = mean2[0]\n",
    "        b1 = a1 - mean1_num\n",
    "        b2 = a2 - mean2_num\n",
    "        top = (b1*b2)\n",
    "        bottom = math.sqrt((b1*b1)*(b2*b2))\n",
    "\n",
    "        if bottom > 0:\n",
    "            print(top/bottom)\n",
    "            intensity = top/bottom\n",
    "            blank_image[y + 1, x + 1] = intensity\n",
    "        elif bottom <= 0:\n",
    "            intensity = 0\n",
    "            blank_image[y+1, x+1] = intensity\n",
    "\n",
    "cv2.imwrite(\"blank_image.png\", blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"result\", res)\n",
    "cv2.imwrite('final_matches.png', res)\n",
    "#cv2.imshow(\"corelation\", img_correlation_map)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKxzz8nlJLEn0wodvz0PXk",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Forensic_SIFT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
